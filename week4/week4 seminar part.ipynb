{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import os\n",
    "#thanks @keskarnitish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate names\n",
    "* Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train NN instead.\n",
    "* Dataset contains ~8k human names from different cultures[in latin transcript]\n",
    "* Objective (toy problem): learn a generative model over names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_token = \" \"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token+name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print 'n samples = ',len(names)\n",
    "for x in names[::1000]:\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  55\n"
     ]
    }
   ],
   "source": [
    "#all unique characters go here\n",
    "tokens = set([c for name in names for c in name])\n",
    "\n",
    "tokens = list(tokens)\n",
    "print 'n_tokens = ',len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!token_to_id = <dictionary of symbol -> its identifier (index in tokens list)>\n",
    "token_to_id = {t:i for i,t in enumerate(tokens) }\n",
    "\n",
    "#!id_to_token = < dictionary of symbol identifier -> symbol itself>\n",
    "id_to_token = {i:t for i,t in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFpIkqRqDhSRJqub/A8xhIvhxLaVsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f738eaeb890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(map(len,names),bins=25);\n",
    "\n",
    "# truncate names longer than MAX_LEN characters. \n",
    "MAX_LEN = 10\n",
    "#ADJUST IF YOU ARE UP TO SOMETHING SERIOUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_ix = list(map(lambda name: list(map(token_to_id.get,name)),names))\n",
    "\n",
    "\n",
    "#crop long names and pad short ones\n",
    "for i in range(len(names_ix)):\n",
    "    names_ix[i] = names_ix[i][:MAX_LEN] #crop too long\n",
    "    \n",
    "    if len(names_ix[i]) < MAX_LEN:\n",
    "        names_ix[i] += [token_to_id[\" \"]]*(MAX_LEN - len(names_ix[i])) #pad too short\n",
    "        \n",
    "assert len(set(map(len,names_ix)))==1\n",
    "\n",
    "names_ix = np.array(names_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequencea','int32')\n",
    "target_values = T.matrix('actual next token','int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build NN\n",
    "\n",
    "You will be building a model that takes token sequence and predicts next token\n",
    "\n",
    "\n",
    "* iput sequence\n",
    "* one-hot / embedding\n",
    "* recurrent layer(s)\n",
    "* otput layer(s) that predict output probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer,DenseLayer,EmbeddingLayer\n",
    "from lasagne.layers import RecurrentLayer,LSTMLayer,GRULayer,CustomRecurrentLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_in = lasagne.layers.InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "\n",
    "#!<Your neural network>\n",
    "l_emb = EmbeddingLayer(l_in, len(tokens), 30)\n",
    "\n",
    "l_rnn = RecurrentLayer(l_emb, 40, nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "#flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "l_rnn_flat = lasagne.layers.reshape(l_rnn, (-1,l_rnn.output_shape[-1]))\n",
    "\n",
    "l_out = DenseLayer(l_rnn_flat, len(tokens), nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, input_to_hidden.W, input_to_hidden.b, hidden_to_hidden.W, W, b]\n"
     ]
    }
   ],
   "source": [
    "# Model weights\n",
    "weights = lasagne.layers.get_all_params(l_out,trainable=True)\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_output = lasagne.layers.get_output(l_out)\n",
    "#If you use dropout do not forget to create deterministic version for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_probabilities_flat = network_output\n",
    "correct_answers_flat = target_values.ravel()\n",
    "\n",
    "loss = lasagne.objectives.categorical_crossentropy(predicted_probabilities_flat,correct_answers_flat).mean()\n",
    "\n",
    "updates = lasagne.updates.sgd(loss,weights,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training\n",
    "train = theano.function([input_sequence, target_values], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#computing loss without training\n",
    "compute_cost = theano.function([input_sequence, target_values], loss, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generation\n",
    "\n",
    "Simple: \n",
    "* get initial context(seed), \n",
    "* predict next token probabilities,\n",
    "* sample next token, \n",
    "* add it to the context\n",
    "* repeat from step 2\n",
    "\n",
    "You'll get a more detailed info on how it works in the homework section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile the function that computes probabilities for next token given previous text.\n",
    "\n",
    "#reshape back into original shape\n",
    "next_word_probas = network_output.reshape((input_sequence.shape[0],input_sequence.shape[1],len(tokens)))\n",
    "#predictions for next tokens (after sequence end)\n",
    "last_word_probas = next_word_probas[:,-1]\n",
    "probs = theano.function([input_sequence],last_word_probas,allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=None,N=MAX_LEN,t=1,n_snippets=1):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "        \n",
    "    parameters:\n",
    "        sample_fun - max_ or proportional_sample_fun or whatever else you implemented\n",
    "        \n",
    "        The phrase is set using the variable seed_phrase\n",
    "\n",
    "        The optional input \"N\" is used to set the number of characters of text to predict.     \n",
    "    '''\n",
    "    if seed_phrase is None:\n",
    "        seed_phrase=start_token\n",
    "    if len(seed_phrase) > MAX_LEN:\n",
    "        seed_phrase = seed_phrase[-MAX_LEN:]\n",
    "    assert type(seed_phrase) is str\n",
    "\n",
    "    snippets = []\n",
    "    for _ in range(n_snippets):\n",
    "        sample_ix = []\n",
    "        x = map(lambda c: token_to_id.get(c,0), seed_phrase)\n",
    "        x = np.array([x])\n",
    "\n",
    "        for i in range(N):\n",
    "            # Pick the character that got assigned the highest probability\n",
    "            p = probs(x).ravel()\n",
    "            p = p**t / np.sum(p**t)\n",
    "            ix = np.random.choice(np.arange(len(tokens)),p=p)\n",
    "            sample_ix.append(ix)\n",
    "\n",
    "            x = np.hstack((x[-MAX_LEN+1:],[[ix]]))\n",
    "\n",
    "        random_snippet = seed_phrase + ''.join(id_to_token[ix] for ix in sample_ix)    \n",
    "        snippets.append(random_snippet)\n",
    "        \n",
    "    print(\"----\\n %s \\n----\" % '; '.join(snippets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "Here you can tweak parameters or insert your generation function\n",
    "\n",
    "\n",
    "__Once something word-like starts generating, try increasing seq_length__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(data, batch_size):\n",
    "    \n",
    "    rows = data[np.random.randint(0,len(data),size=batch_size)]\n",
    "    \n",
    "    return rows[:,:-1],rows[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Generated names\n",
      "----\n",
      "   wjwHsr'QF;  mnczgpaYvF;  'O tlibUUX;  ujsbdOTzVn;  mcPLZoKMAf;  K'FvuVrnzW;  TGkZOVqrHd;  HGRgpX mQI;  hgObOoWpAO;  oHPilJDobi \n",
      "----\n",
      "Epoch 0 average loss = 3.2060846796\n",
      "Generated names\n",
      "----\n",
      "  nY Bh  j e;  jUAG   Jr ;  tg   A  nP;  AWjf  a en;  iv d a i n;  Qama Qdu  ;  sXul i s u;  rd  ai    ;  w- dB ii r;  Hi      rl \n",
      "----\n",
      "Epoch 1 average loss = 2.64227847682\n",
      "Generated names\n",
      "----\n",
      "  JYRtC r  T;  F GPUl   O;  qjr   a e-;  MfahH GM  ;  uLeoLr ii ;   ic V nena;  lp aivBlH ;  nzlu a  re;  J a a e if;   ah ne e   \n",
      "----\n",
      "Epoch 2 average loss = 2.51085075482\n",
      "Generated names\n",
      "----\n",
      "  U'yti Sn  ;  Eiteii  n ;  teye fe e ;  pe FeM   i;  yYirn e n ;  Ds'ate n  ;  sCYci  e  ;  F Inn     ;  pCeny ss  ;  tyiya      \n",
      "----\n",
      "Epoch 3 average loss = 2.4178942103\n",
      "Generated names\n",
      "----\n",
      "  mtinyn r  ;  qyMIoei   ;  KFJs e    ;  vVaiwe   i;  uSatili   ;  iaEdOn    ;  htQeh     ;  ywnrZ     ;  TUeeeol   ;  unie e     \n",
      "----\n",
      "Epoch 4 average loss = 2.36325370339\n",
      "Generated names\n",
      "----\n",
      "  LwtAhPa r ;  ujuddk    ;  BIAot     ;  ialrsi    ;  AarrDi    ;  CrRce     ;  pdaeea  e ;  hmrs e   n;  Ge a a    ;  uArnre     \n",
      "----\n",
      "Epoch 5 average loss = 2.32447513531\n",
      "Generated names\n",
      "----\n",
      "  aun l     ;  JZati     ;  'olaas    ;  lr-al     ;  hTres     ;  aaVe      ;  enilO     ;  Qper e    ;  cBiere    ;  pydiln     \n",
      "----\n",
      "Epoch 6 average loss = 2.2885732988\n",
      "Generated names\n",
      "----\n",
      "  larerlb   ;  ehihil    ;  iirmil    ;  Baeist    ;  Cbitae    ;   dambl  n ;  zdCenyl   ;  LEalxaa  a;  ntelrd e  ;  yaenre r   \n",
      "----\n",
      "Epoch 7 average loss = 2.24663996027\n",
      "Generated names\n",
      "----\n",
      "  MAoke    e;  ilrrn     ;  laenat a  ;  yanrn o   ;  rmriiy  e ;  diMa      ;  r-holri   ;  FysaAet   ;  Yyerno    ;  Srlni      \n",
      "----\n",
      "Epoch 8 average loss = 2.22373589455\n",
      "Generated names\n",
      "----\n",
      "  nmalit    ;  aVernitt  ;  Plelnlq   ;  lWehst    ;  Nai- nd   ;  segan l   ;  oaaeli    ;  wItae     ;  Phiyll    ;  Nildho     \n",
      "----\n",
      "Epoch 9 average loss = 2.16905821844\n",
      "Generated names\n",
      "----\n",
      "  Nihare s  ;  Dcyea     ;  Beyaee    ;  Djri h    ;    r       ;  airn      ;  EVtei     ;  aprrlSi   ;  Caoyim    ;  Kdyn       \n",
      "----\n",
      "Epoch 10 average loss = 2.13802426958\n",
      "Generated names\n",
      "----\n",
      "  argli m   ;  Llbym     ;  hoceomio  ;  oisve     ;  'odene    ;  cOosi  a  ;  Iuolnin   ;  Etrb      ;  OAoeailn  ;  eIiilaie   \n",
      "----\n",
      "Epoch 11 average loss = 2.10290537292\n",
      "Generated names\n",
      "----\n",
      "  Jararn    ;  bektgiann ;  Eaaaeg    ;  Erntif    ;  Eyal      ;  CEbam     ;  TrciLFpe  ;  Vne       ;  CMlFk     ;  iccee      \n",
      "----\n",
      "Epoch 12 average loss = 2.08633580469\n",
      "Generated names\n",
      "----\n",
      "  Mpvuia    ;   wid      ;  Reunrneai ;  Faaiaee   ;  Melrc     ;  Earmeeaia ;  Baest     ;   Drdn     ;  nhunira   ;  Aaasry     \n",
      "----\n",
      "Epoch 13 average loss = 2.05987186046\n",
      "Generated names\n",
      "----\n",
      "  Dlyltn    ;  vbiedtare ;  xiete     ;  Donlnoe   ;  Melnc     ;  Admrn     ;  -dcee     ;  Rarsrne   ;  ladyi     ;  Baht       \n",
      "----\n",
      "Epoch 14 average loss = 2.04130920553\n",
      "Generated names\n",
      "----\n",
      "  idsdea    ;  qrycan    ;  Vernse    ;  fpree     ;  Wasdkj    ;  SEraite   ;  Toene     ;  Waoere    ;  Riaite    ;  Movlenie   \n",
      "----\n",
      "Epoch 15 average loss = 2.02139501545\n",
      "Generated names\n",
      "----\n",
      "  Yhrrscvkbi;  JaEee     ;  Firen     ;   ran      ;  CQhdna    ;  Toina     ;  Fibte     ;  Jieneo    ;  Xyyrd     ;  klucta     \n",
      "----\n",
      "Epoch 16 average loss = 2.01329316558\n",
      "Generated names\n",
      "----\n",
      "  Yaln      ;  Lasta     ;  uobd      ;  Lhuniy    ;  Clihr     ;  Mclailctnh;  rauhdi    ;  lEelre    ;  Mirtity   ;  XAinell    \n",
      "----\n",
      "Epoch 17 average loss = 2.01248519826\n",
      "Generated names\n",
      "----\n",
      "  vare      ;  Kabmn     ;  Hlllnltrir;  Hrezea    ;  Eewrs     ;  Brrnnei   ;  Noyy      ;  Resle     ;  FLnsna    ;  Kegis      \n",
      "----\n",
      "Epoch 18 average loss = 1.98853700747\n",
      "Generated names\n",
      "----\n",
      "  Rhraio    ;  Heme      ;  Sriratettu;  Telmnre   ;  Haliia    ;  E-ltita   ;  Voky      ;  PJiay     ;  Phals     ;  CDeneg     \n",
      "----\n",
      "Epoch 19 average loss = 1.99768051544\n",
      "Generated names\n",
      "----\n",
      "  Jiei      ;  Mhinm     ;  Tdiori    ;  Ahhinxt   ;  Iaenh     ;  Lrrler    ;  Tiymnne   ;  Eymfee    ;  MaieaFa   ;  Wabesw     \n",
      "----\n",
      "Epoch 20 average loss = 1.9792871293\n",
      "Generated names\n",
      "----\n",
      "  Ehacie    ;  Garbllnnnn;   erda     ;  Corertia  ;  Kyue      ;  Lanon     ;  Nildnn    ;  Heritlola ;  Smbie     ;  Delanyd    \n",
      "----\n",
      "Epoch 21 average loss = 1.97747670085\n",
      "Generated names\n",
      "----\n",
      "  Rrt       ;  Moedistien;  Nanoe     ;  Aeles     ;  Gatra     ;  Joen      ;  Eninea    ;  Cinyy     ;  Lscra     ;  Jeuldsa    \n",
      "----\n",
      "Epoch 22 average loss = 1.98244478526\n",
      "Generated names\n",
      "----\n",
      "  Iarrniu   ;  Janlm     ;  Jaiba     ;  Aannlarnn ;  Tare      ;  Botvnl    ;  Asdlta    ;  Jaedda    ;  Cunna     ;  Fidta      \n",
      "----\n",
      "Epoch 23 average loss = 1.97513624638\n",
      "Generated names\n",
      "----\n",
      "  Hatyiu    ;  Eeni      ;  Roryl     ;  Cdpnaryo  ;  Couialihra;  Vdcy      ;  Kiica     ;  Mhurpeo   ;  Gote      ;  Wugkta     \n",
      "----\n",
      "Epoch 24 average loss = 1.96992277616\n",
      "Generated names\n",
      "----\n",
      "  Stn       ;  Terta     ;  Blbnos    ;  Jalyni    ;  Nacna     ;  Soybetb   ;  Soeie     ;  Jolta     ;  Lanlh     ;  Foag       \n",
      "----\n",
      "Epoch 25 average loss = 1.96720487679\n",
      "Generated names\n",
      "----\n",
      "  Kelal     ;  Hovde     ;  Merqssiny ;  Shlhmiart ;  Leblri    ;  Wonr      ;  Airn      ;  Lytaka    ;  AinaUn    ;  Drnsna     \n",
      "----\n",
      "Epoch 26 average loss = 1.94419098457\n",
      "Generated names\n",
      "----\n",
      "  Daitnssne ;  Tnvktlta  ;  Hays      ;  Sre       ;  Coehae    ;  Qrodlyl   ;  Eadeoe    ;  Sulgtea   ;  Joisne    ;  Eeaio      \n",
      "----\n",
      "Epoch 27 average loss = 1.97268777946\n",
      "Generated names\n",
      "----\n",
      "  MaAnsea   ;  Dentienca ;  Kunfeee   ;  Loceti    ;  Gadts     ;  Juenta    ;  Wirif     ;  Igrante   ;  DrleXe    ;  Aeelglrvyn \n",
      "----\n",
      "Epoch 28 average loss = 1.94833360973\n",
      "Generated names\n",
      "----\n",
      "  Argre     ;  Yai       ;  Maly      ;  YevTi     ;  Saasr     ;  Narttm    ;  Aiaalnsne ;  Miaa      ;  Srdna     ;  Koonalerne \n",
      "----\n",
      "Epoch 29 average loss = 1.95305602034\n",
      "Generated names\n",
      "----\n",
      "  Bloen     ;  Saral     ;  Nnoga     ;  Chafy     ;  Plmha-    ;  Norga     ;  Gcinne    ;  Tnsa      ;  Asary     ;  Bamedbe    \n",
      "----\n",
      "Epoch 30 average loss = 1.95227286739\n",
      "Generated names\n",
      "----\n",
      "  Manlihn   ;  Hihve     ;  Caa       ;  Malda     ;  Ailone    ;  Gihay     ;  Aakome    ;  Tar       ;  Cinbte    ;  fuercena   \n",
      "----\n",
      "Epoch 31 average loss = 1.95588751211\n",
      "Generated names\n",
      "----\n",
      "  Tar       ;  Ferirtoa  ;  Tilutie   ;  Laavirpda ;  Maodlgen  ;  Konys ra  ;  Poan      ;  Whally    ;  Rdcline   ;  Cf         \n",
      "----\n",
      "Epoch 32 average loss = 1.94485696218\n",
      "Generated names\n",
      "----\n",
      "  Kera      ;  Brlsare   ;  Fiyctsa   ;  Ihclgo    ;  Tolbnta   ;  Anerne    ;  Wanalke   ;  Kodl      ;  Plnsten   ;  Mekea      \n",
      "----\n",
      "Epoch 33 average loss = 1.93574902517\n",
      "Generated names\n",
      "----\n",
      "  Ransrine  ;  Ferezse   ;  Airne     ;  Maloe     ;  Hidita na ;  Celsaa    ;  Gora      ;  Dewori    ;  Eelbinea  ;  RErale     \n",
      "----\n",
      "Epoch 34 average loss = 1.9241717805\n",
      "Generated names\n",
      "----\n",
      "  Rarien    ;  Cera      ;  Suliide   ;  Jociny    ;  Sedalitc  ;  Jloha     ;  Fanina    ;  Fadibva   ;  Setalia   ;  Airega     \n",
      "----\n",
      "Epoch 35 average loss = 1.91202028896\n",
      "Generated names\n",
      "----\n",
      "  Domma     ;  Reboli    ;  Mebdse    ;  Koage     ;  Hiriha    ;  Rdse      ;  Eodix     ;  Meli      ;  Midoa     ;  Roerare    \n",
      "----\n",
      "Epoch 36 average loss = 1.92388923271\n",
      "Generated names\n",
      "----\n",
      "  Tnsgda    ;  Ebezntbat ;  Cilomda   ;  Oortil    ;  Majie n   ;  Srldstfde ;  Jarhralno ;  Fees      ;  Cesdarien ;  Lahl       \n",
      "----\n",
      "Epoch 37 average loss = 1.91781947177\n",
      "Generated names\n",
      "----\n",
      "  Rannanlo  ;  Tdklla    ;  Prcinn    ;  Jasana    ;  Ontsi     ;  Cnana     ;  Clcry     ;  Fhetera   ;  Firnoa    ;  Septan     \n",
      "----\n",
      "Epoch 38 average loss = 1.8949254526\n",
      "Generated names\n",
      "----\n",
      "  BaXonlrih ;  Sodtoa    ;  EAniwue   ;  Kvnee     ;  Llid      ;  Dendne    ;  Dalyyni   ;  Jeytaoad  ;  Surarede  ;  Ghlase     \n",
      "----\n",
      "Epoch 39 average loss = 1.90333050732\n",
      "Generated names\n",
      "----\n",
      "  Sapla     ;  Belonane  ;  DseGo     ;  Matehotdia;  Kinena    ;  Sotceca   ;  Ansacren  ;  Heagoi    ;  Jemlt     ;  Phalanli   \n",
      "----\n",
      "Epoch 40 average loss = 1.90641837258\n",
      "Generated names\n",
      "----\n",
      "  Alilgys   ;  Konit     ;  Sance     ;  Kirfanf   ;  Heresa    ;  Lerii     ;  Naruzre   ;  Lati      ;  Miria     ;  Smd        \n",
      "----\n",
      "Epoch 41 average loss = 1.88831711802\n",
      "Generated names\n",
      "----\n",
      "  Lirle     ;  Velie     ;  Dlibiena  ;  Xorwas    ;  Fiyrez    ;  Suntisi   ;  TMily     ;  RieB      ;  Vaa       ;  Doteno     \n",
      "----\n",
      "Epoch 42 average loss = 1.89677721423\n",
      "Generated names\n",
      "----\n",
      "  Carar     ;  Tarrite   ;  Sem       ;  Laretag   ;  Cssct     ;  Saliasn   ;  Vurie     ;  Gegy      ;  Dlanfe    ;  Rerdf      \n",
      "----\n",
      "Epoch 43 average loss = 1.89763502379\n",
      "Generated names\n",
      "----\n",
      "  Sole      ;  Irtiloe   ;  Fobidnco  ;  Dawd      ;  Ndalizly  ;  Oisba     ;  Locdiinnda;  Gellein   ;  Zhre      ;  Heulse     \n",
      "----\n",
      "Epoch 44 average loss = 1.88230623743\n",
      "Generated names\n",
      "----\n",
      "  Heti      ;  Woeona    ;  Gare      ;  Iexte     ;  Bocat     ;  Rlnrilenr ;  Geri      ;  Gallela   ;  Nerykx-a  ;  Khbita     \n",
      "----\n",
      "Epoch 45 average loss = 1.88806776545\n",
      "Generated names\n",
      "----\n",
      "  Rrtyn     ;  Meckile   ;  Llada     ;  Dadida    ;  Hhoa t    ;  Womteso   ;  Sarina    ;  Rer       ;  Ahy       ;  Khia       \n",
      "----\n",
      "Epoch 46 average loss = 1.88062033953\n",
      "Generated names\n",
      "----\n",
      "  Wadmta    ;  Grik      ;  E         ;  Behaly   n;  Bhden     ;  Sogde     ;  Julta     ;  uende     ;  Botdi     ;  Ahlesst    \n",
      "----\n",
      "Epoch 47 average loss = 1.8877729771\n",
      "Generated names\n",
      "----\n",
      "  Olapnara  ;  Lhlinna   ;  Sodca     ;  Veriento  ;  Jriclen   ;  Aisale    ;  Srittisa  ;  Roberevy  ;  Iur       ;  Adci       \n",
      "----\n",
      "Epoch 48 average loss = 1.88949790416\n",
      "Generated names\n",
      "----\n",
      "  Cattatiua ;  Bri       ;  Blasnc    ;  Mnys      ;  Sirlahten ;  Lemba     ;  Lersee    ;  Ogantene  ;  Iengsidl  ;  Rerhtie    \n",
      "----\n",
      "Epoch 49 average loss = 1.87754524091\n",
      "Generated names\n",
      "----\n",
      "  Lialt     ;  Aumena    ;  Kllii     ;  Sltisi    ;  Wlany     ;  Jlan      ;  Locvi     ;  Gallaen   ;  Tirmela   ;  Klcfonua   \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print(\"Training ...\")\n",
    "\n",
    "#total N iterations\n",
    "n_epochs=100\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "batches_per_epoch = 500\n",
    "\n",
    "#how many training sequences are processed in a single function call\n",
    "batch_size=10\n",
    "\n",
    "for epoch in xrange(n_epochs):\n",
    "\n",
    "    print \"Generated names\"\n",
    "    generate_sample(n_snippets=10)\n",
    "\n",
    "    avg_cost = 0;\n",
    "    \n",
    "    for _ in range(batches_per_epoch):\n",
    "        \n",
    "        x,y = sample_batch(names_ix,batch_size)\n",
    "        avg_cost += train(x, y)\n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_sample(n_snippets=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_sample(seed=\" A\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
