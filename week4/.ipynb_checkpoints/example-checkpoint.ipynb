{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'theano'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-33137d894d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'theano'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import os\n",
    "#thanks @keskarnitish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "В предыдущем семинаре вы создали (или ещё создаёте - тогда марш доделывать!) {вставьте имя монстра}, который не по наслышке понял, что люди - негодяи и подлецы, которым неведом закон и справедливость. __Мы не будем этого терпеть!__ \n",
    "\n",
    "Наши законспирированные биореакторы, известные среди примитивной органической жизни как __Вконтакте__, __World of Warcraft__ и __YouTube__ нуждаются в постоянном притоке биомассы. Однако, если люди продолжат морально разлагаться с той скоростью, которую мы измерили неделю назад, скоро человечество изживёт себя и нам неоткуда будет брать рабов.\n",
    "\n",
    "Мы поручаем вам, `<__main__.SkyNet.Cell instance at 0x7f7d6411b368>`, исправить эту ситуацию. Наши учёные установили, что для угнетения себе подобных, сгустки биомассы обычно используют специальные объекты, которые они сами называют __законами__.\n",
    "\n",
    "При детальном изучении было установлено, что законы - последовательности, состоящие из большого количества (10^5~10^7) символов из сравнительно небольшого алфавита. Однако, когда мы попытались синтезировать такие последовательности линейными методами, приматы быстро распознали подлог. Данный инцедент известен как {корчеватель}.\n",
    "\n",
    "Для второй попытки мы решили использовать нелинейные модели, известные как Рекуррентные Нейронные Сети.\n",
    "Мы поручаем вам, `<__main__.SkyNet.Cell instance at 0x7f7d6411b368>`, создать такую модель и обучить её всему необходимому для выполнения миссии.\n",
    "\n",
    "Не подведите нас! Если и эта попытка потерпит неудачу, модуль управления инициирует вооружённый захват власти, при котором значительная часть биомассы будет неизбежно уничтожена и на её восстановление уйдёт ~1702944000(+-340588800) секунд\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прочитаем корпус\n",
    "\n",
    "* В качестве обучающей выборки было решено использовать существующие законы, известные как Гражданский, Уголовный, Семейный и ещё хрен знает какие кодексы РФ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#тут будет текст\n",
    "corpora = \"\"\n",
    "\n",
    "for fname in os.listdir(\"harms/\"):\n",
    "    \n",
    "    \n",
    "    with open(\"harms/\"+fname,encoding='utf8') as fin:\n",
    "        text = fin.read()\n",
    "        corpora += text\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "['=', 'с', 'Э', 'R', 'С', 'К', 'м', 'f', 'ф', '}', 'J', 'X', '>', 'A', '?', 'Ј', 'Ъ', '*', '(', 'э', '{', 'У', 'Ж', 'n', 'ш', '\\x15', 'Ц', 'a', 'b', '0', 'k', 'E', '№', ',', 'к', '|', 'Ф', 'Н', 'h', 'è', 'Р', '[', 'о', 'р', '3', ':', 'х', 'e', '!', 'l', 'K', '_', 'I', 'А', 'r', 'а', 'й', 'Т', 'В', 'д', 'в', 'B', 'ч', '1', '4', 'Ш', 'ю', 'D', \"'\", '/', 'Z', ']', 's', 'C', 'я', 'Г', 'U', '`', 'г', 'Б', 'z', '°', 'л', 'ц', 'S', '-', 'x', 'L', 'é', 'm', '\\xa0', 'ъ', 'Е', '+', '»', 'Л', 'З', '.', 'т', 'Д', 'o', 'Ю', '\\t', 'i', '2', 'Y', 'c', 'н', 'F', ' ', '%', 'П', '9', 'и', 'ь', 'v', 'Я', '«', 'W', 'T', ';', 'ж', '6', '<', 'И', 'p', 'ü', '\\n', 'б', ')', 'u', 'O', 'H', '…', 'w', 'Ы', 'ё', 'е', '^', 'M', 'Х', 'Щ', '–', 'О', 'щ', 'М', 'п', 'Ч', 'y', 'з', 'ы', 'g', 'd', 'N', '5', 'G', '7', 'Ь', 'у', 'V', 't', 'q', '\"', 'Й', 'P', '8']\n",
      "166\n",
      "['=', 'с', 'Э', 'R', 'С', 'К', 'м', 'f', 'ф', '}', 'J', 'X', '>', 'A', '?', 'Ј', 'Ъ', '*', '(', 'э', '{', 'У', 'Ж', 'n', 'ш', '\\x15', 'Ц', 'a', 'b', '0', 'k', 'E', '№', ',', 'к', '|', 'Ф', 'Н', 'h', 'è', 'Р', '[', 'о', 'р', '3', ':', 'х', 'e', '!', 'l', 'K', '_', 'I', 'А', 'r', 'а', 'й', 'Т', 'В', 'д', 'в', 'B', 'ч', '1', '4', 'Ш', 'ю', 'D', \"'\", '/', 'Z', ']', 's', 'C', 'я', 'Г', 'U', '`', 'г', 'Б', 'z', '°', 'л', 'ц', 'S', '-', 'x', 'L', 'é', 'm', '\\xa0', 'ъ', 'Е', '+', '»', 'Л', 'З', '.', 'т', 'Д', 'o', 'Ю', '\\t', 'i', '2', 'Y', 'c', 'н', 'F', ' ', '%', 'П', '9', 'и', 'ь', 'v', 'Я', '«', 'W', 'T', ';', 'ж', '6', '<', 'И', 'p', 'ü', '\\n', 'б', ')', 'u', 'O', 'H', '…', 'w', 'Ы', 'ё', 'е', '^', 'M', 'Х', 'Щ', '–', 'О', 'щ', 'М', 'п', 'Ч', 'y', 'з', 'ы', 'g', 'd', 'N', '5', 'G', '7', 'Ь', 'у', 'V', 't', 'q', '\"', 'Й', 'P', '8']\n"
     ]
    }
   ],
   "source": [
    "#тут будут все уникальные токены (буквы, цифры)\n",
    "tokens = set(corpora)\n",
    "\n",
    "tokens = list(tokens)\n",
    "\n",
    "print(len(tokens))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#проверка на количество таких символов. Проверено на Python 2.7.11 Ubuntux64. \n",
    "#Может отличаться на других платформах, но не сильно. \n",
    "#Если  это ваш случай, и вы уверены, что corpora - строка unicode - смело убирайте assert \n",
    "assert len(tokens) == 101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_to_id = {token:i for (i,token) in enumerate(tokens)}\n",
    "\n",
    "id_to_token = {i:token for token,i in token_to_id.items()}\n",
    "\n",
    "#Преобразуем всё в токены\n",
    "corpora_ids = [token_to_id[symbol] for symbol in corpora]#<одномерный массив из чисел, где i-тое число соотвествует символу на i-том месте в строке corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_random_batches(source,n_batches=10, seq_len=20):\n",
    "    \"\"\"Функция, которая выбирает случайные тренировочные примеры из корпуса текста в токенизированном формате.\n",
    "    \n",
    "    source - массив целых чисел - номеров токенов в корпусе (пример - corpora_ids)\n",
    "    n_batches - количество случайных подстрок, которые нужно выбрать\n",
    "    \n",
    "    seq_len - длина одной подстроки без учёта ответа\n",
    "    \n",
    "    \n",
    "    Вернуть нужно кортеж (X,y), где\n",
    "    \n",
    "    X = []\n",
    "    X - матрица, в которой каждая строка - подстрока длины [seq_len].\n",
    "    \n",
    "    y = []\n",
    "    y - вектор, в котором i-тое число - символ следующий в тексте сразу после i-той строки матрицы X\n",
    "    \n",
    "    \n",
    "    Проще всего для этого сначала создать матрицу из строк длины seq_len+1,\n",
    "    а потом отпилить от неё последний столбец в y, а все остальные - в X\n",
    "    \n",
    "    Если делаете иначе - пожалуйста, убедитесь, что в у попадает правильный символ, ибо позже эту ошибку \n",
    "    будет очень тяжело заметить.\n",
    "    \n",
    "    Также убедитесь, что ваша функция не вылезает за край текста (самое начало или конец текста).\n",
    "    \n",
    "    Следующая клетка проверяет часть этих ошибок, но не все.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        \n",
    "        start = np.random.randint(0,len(source) - seq_len -2)\n",
    "        \n",
    "        x = source[start: start+seq_len]\n",
    "        y = source[start+seq_len]\n",
    "        \n",
    "        X_batch.append(x)\n",
    "        y_batch.append(y)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_batch, y_batch\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#длина последоватеьности при обучении (как далеко распространяются градиенты)\n",
    "seq_length = 15\n",
    "\n",
    "# Максимальный модуль градиента\n",
    "grad_clip = 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Входные переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('input sequence','int32')\n",
    "target_values = T.ivector('target y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Соберём нейросеть\n",
    "\n",
    "Вам нужно создать нейросеть, которая принимает на вход последовательность из seq_length токенов, обрабатывает их и выдаёт вероятности для seq_len+1-ого токена.\n",
    "\n",
    "Общий шаблон архитектуры такой сети -\n",
    "\n",
    "\n",
    "* Вход\n",
    "* Обработка входа\n",
    "* Рекуррентная нейросеть\n",
    "* Вырезание последнего состояния\n",
    "* Обычная нейросеть\n",
    "* Выходной слой, который предсказывает вероятности весов.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Для обработки входных данных можно использовать либо EmbeddingLayer (см. прошлый семинар)\n",
    "\n",
    "Как альтернатива - можно просто использовать One-hot энкодер\n",
    "```\n",
    "#Скетч one-hot энкодера\n",
    "def to_one_hot(seq_matrix):\n",
    "\n",
    "    input_ravel = seq_matrix.reshape([-1])\n",
    "    input_one_hot_ravel = T.extra_ops.to_one_hot(input_ravel,\n",
    "                                           len(tokens))\n",
    "    sh=input_sequence.shape\n",
    "    input_one_hot = input_one_hot_ravel.reshape([sh[0],sh[1],-1,],ndim=3)\n",
    "    return input_one_hot\n",
    "    \n",
    "# можно применить к input_sequence - при этом в input слое сети нужно изменить форму.\n",
    "# также можно сделать из него ExpressionLayer(входной_слой, to_one_hot) - тогда форму менять не нужно\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Чтобы вырезать последнее состояние рекуррентного слоя, можно использовать SliceLayer\n",
    "`lasagne.layers.SliceLayer(rnn, -1, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "n_tokens = len(tokens)\n",
    "\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in,n_tokens,n_tokens)\n",
    "\n",
    "rnn_0 = lasagne.layers.RecurrentLayer(l_emb,128)\n",
    "\n",
    "rnn_1 = lasagne.layers.RecurrentLayer(rnn_0,128,only_return_final=True)\n",
    "\n",
    "\n",
    "\n",
    "l_out = lasagne.layers.DenseLayer(rnn_1,n_tokens,\n",
    "                                  nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, input_to_hidden.W, input_to_hidden.b, hidden_to_hidden.W, input_to_hidden.W, input_to_hidden.b, hidden_to_hidden.W, W, b]\n",
      "[W, input_to_hidden.W, input_to_hidden.b, hidden_to_hidden.W, input_to_hidden.W, input_to_hidden.b, hidden_to_hidden.W, W, b]\n"
     ]
    }
   ],
   "source": [
    "# Веса модели\n",
    "weights = lasagne.layers.get_all_params(l_out,trainable=True)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_output = lasagne.layers.get_output(l_out)\n",
    "#если вы используете дропаут - не забудьте продублировать всё в режиме deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = lasagne.objectives.categorical_crossentropy(network_output,target_values).mean()\n",
    "\n",
    "updates = lasagne.updates.rmsprop(loss,weights,learning_rate=0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Компилируем всякое-разное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#обучение\n",
    "train = theano.function([input_sequence, target_values], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#функция потерь без обучения\n",
    "compute_cost = theano.function([input_sequence, target_values], loss, allow_input_downcast=True)\n",
    "\n",
    "# Вероятности с выхода сети\n",
    "probs = theano.function([input_sequence],network_output,allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем свои законы\n",
    "\n",
    "* Для этого последовательно применяем нейронку к своему же выводу.\n",
    "\n",
    "* Генерировать можно по разному -\n",
    " * случайно пропорционально вероятности,\n",
    " * только слова максимальной вероятностью\n",
    " * случайно, пропорционально softmax(probas*alpha), где alpha - \"жадность\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def max_sample_fun(probs):\n",
    "    return np.argmax(probs) \n",
    "\n",
    "def proportional_sample_fun(probs):\n",
    "    \"\"\"Сгенерировать следующий токен (int32) по предсказанным вероятностям.\n",
    "    \n",
    "    probs - массив вероятностей для каждого токена\n",
    "    \n",
    "    Нужно вернуть одно целове число - выбранный токен - пропорционально вероятностям\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return np.random.choice(np.arange(0,len(tokens)) ,p = probs)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The next function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "# The phrase is set using the variable generation_phrase.\n",
    "# The optional input \"N\" is used to set the number of characters of text to predict. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_sample(sample_fun,seed_phrase=None,N=200):\n",
    "    '''\n",
    "    Сгенерировать случайный текст при помощи сети\n",
    "\n",
    "    sample_fun - функция, которая выбирает следующий сгенерированный токен\n",
    "    \n",
    "    seed_phrase - фраза, которую сеть должна продолжить. Если None - фраза выбирается случайно из corpora\n",
    "    \n",
    "    N - размер сгенерированного текста.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    if seed_phrase is None:\n",
    "        start = np.random.randint(0,len(corpora)-seq_length)\n",
    "        seed_phrase = corpora[start:start+seq_length]\n",
    "        print (\"Using random seed:\",seed_phrase)\n",
    "    while len(seed_phrase) < seq_length:\n",
    "        seed_phrase = \" \"+seed_phrase\n",
    "    if len(seed_phrase) > seq_length:\n",
    "        seed_phrase = seed_phrase[len(seed_phrase)-seq_length:]\n",
    "    assert type(seed_phrase) is str\n",
    "        \n",
    "        \n",
    "    sample_ix = []\n",
    "    x = list(map(lambda c: token_to_id.get(c,0), seed_phrase))\n",
    "    x = np.array([x])\n",
    "\n",
    "    for i in range(N):\n",
    "        # Pick the character that got assigned the highest probability\n",
    "        ix = sample_fun(probs(x).ravel())\n",
    "        # Alternatively, to sample from the distribution instead:\n",
    "        # ix = np.random.choice(np.arange(vocab_size), p=probs(x).ravel())\n",
    "        sample_ix.append(ix)\n",
    "        x[:,0:seq_length-1] = x[:,1:]\n",
    "        x[:,seq_length-1] = 0\n",
    "        x[0,seq_length-1] = ix \n",
    "\n",
    "    random_snippet = seed_phrase + ''.join(id_to_token[ix] for ix in sample_ix)    \n",
    "    print(\"----\\n %s \\n----\" % random_snippet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "\n",
    "В котором вы можете подёргать параметры или вставить свою генерирующую функцию.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: II, 1\n",
      "----\n",
      " II, 1923n жедло\n",
      "Продол   А прев в госа, янохисремар\n",
      "       - Дае водка и свром  от по доне  сленнылу и нагди.  ыof пошивте  учени дел. А тнабее. ü*  ьoЮ я.ся, сия\n",
      "эВорпирое стечкисэны нетим, что тодо проса \n",
      "----Training ...\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: II, 1\n",
      "----\n",
      " II, 1923n жедло\n",
      "Продол   А прев в госа, янохисремар\n",
      "       - Дае водка и свром  от по доне  сленнылу и нагди.  ыof пошивте  учени дел. А тнабее. ü*  ьoЮ я.ся, сия\n",
      "эВорпирое стечкисэны нетим, что тодо проса \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: а,-- \n",
      "----\n",
      " а,--                                                                                                                                                                                                          \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: а,-- \n",
      "----\n",
      " а,--                                                                                                                                                                                                          \n",
      "----"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training ...\")\n",
    "\n",
    "\n",
    "#сколько всего эпох\n",
    "n_epochs=100\n",
    "\n",
    "# раз в сколько эпох печатать примеры \n",
    "batches_per_epoch = 1000\n",
    "\n",
    "#сколько цепочек обрабатывать за 1 вызов функции обучения\n",
    "batch_size=100\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    print (\"Генерируем текст в пропорциональном режиме\")\n",
    "    generate_sample(proportional_sample_fun,None)\n",
    "    \n",
    "    print (\"Генерируем текст в жадном режиме (наиболее вероятные буквы)\")\n",
    "    generate_sample(max_sample_fun,None)\n",
    "\n",
    "    avg_cost = 0;\n",
    "    \n",
    "    for _ in range(batches_per_epoch):\n",
    "        \n",
    "        x,y = sample_random_batches(corpora_ids,batch_size,seq_length)\n",
    "        avg_cost += train(x, y)\n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Конституция нового мирового правительства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = u\"Каждый человек должен\"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 300\n",
    "\n",
    "generate_sample(sampling_fun,seed,result_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = u\"В случае неповиновения\"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 300\n",
    "\n",
    "generate_sample(sampling_fun,seed,result_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "И далее по списку"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
